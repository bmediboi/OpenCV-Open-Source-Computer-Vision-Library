{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf8446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\91630\\anaconda3.a\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\91630\\anaconda3.a\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c58cea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e30a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image using 'imread' specifying the path to image\n",
    "image = cv2.imread('C:/Users/91630/Downloads/husky.jpg',0)\n",
    "\n",
    "# Our file 'input.jpg' is now loaded and stored in python \n",
    "# as a varaible we named 'image'\n",
    "\n",
    "# To display our image variable, we use 'imshow'\n",
    "# The first parameter will be title shown on image window\n",
    "# The second parameter is the image varialbe\n",
    "cv2.imshow(\"test image\", image)\n",
    "\n",
    "# 'waitKey' allows us to input information when a image window is open\n",
    "# By leaving it blank it just waits for anykey to be pressed before \n",
    "# By placing numbers (except 0), we can specify a delay for how long you keep the window open (time is in milliseconds here)\n",
    "cv2.waitKey()\n",
    "\n",
    "# This closes all open windows \n",
    "# Failure to place this will cause your program to hang\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8515a6",
   "metadata": {},
   "source": [
    "# Let's take a closer look at how images are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ebf0ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[198 139  53]\n",
      "  [199 140  54]\n",
      "  [198 141  56]\n",
      "  ...\n",
      "  [212 132   1]\n",
      "  [211 131   0]\n",
      "  [211 131   0]]\n",
      "\n",
      " [[198 139  53]\n",
      "  [199 140  54]\n",
      "  [198 141  56]\n",
      "  ...\n",
      "  [212 132   1]\n",
      "  [211 131   0]\n",
      "  [210 130   0]]\n",
      "\n",
      " [[198 140  51]\n",
      "  [199 141  52]\n",
      "  [200 141  55]\n",
      "  ...\n",
      "  [209 131   0]\n",
      "  [208 130   0]\n",
      "  [208 130   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 46 125 176]\n",
      "  [ 61 140 191]\n",
      "  [ 70 149 200]\n",
      "  ...\n",
      "  [ 20  36  65]\n",
      "  [ 25  42  75]\n",
      "  [ 59  76 109]]\n",
      "\n",
      " [[ 49 134 184]\n",
      "  [ 48 133 183]\n",
      "  [ 47 130 181]\n",
      "  ...\n",
      "  [  0   3  33]\n",
      "  [  1  10  44]\n",
      "  [ 41  50  84]]\n",
      "\n",
      " [[ 56 145 195]\n",
      "  [ 58 147 197]\n",
      "  [ 64 149 199]\n",
      "  ...\n",
      "  [ 64  69 100]\n",
      "  [ 30  34  69]\n",
      "  [  0   3  38]]]\n"
     ]
    }
   ],
   "source": [
    "## Images are stored as numpy arrays\n",
    "\n",
    "print(image) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a52ac9",
   "metadata": {},
   "source": [
    "# Shape gives the dimensions of the image array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8afade9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1200, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape   ## (height, width, channels)  ## for colourful images with RGB the channels will be 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9e6bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 231, 3)\n"
     ]
    }
   ],
   "source": [
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ae8257",
   "metadata": {},
   "source": [
    "# Basic image processing Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a80384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resizing the image\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image1 = cv2.imread('C:/Users/91630/Downloads/husky.jpg', 1)\n",
    "\n",
    "# Resize the image, set the desired new image size\n",
    "resized = cv2.resize(image1, (600, 500))\n",
    "\n",
    "# Convert the resized image to grayscale\n",
    "gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Display the original and resized images\n",
    "cv2.imshow(\"Original Image\", image1)\n",
    "cv2.imshow(\"Resized Image\", resized)\n",
    "cv2.imshow(\"Grayscale Image\", gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187b873f",
   "metadata": {},
   "source": [
    "### Image filtering: OpenCV provides various functions for applying filters to images, such as Gaussian blur, median blur, and bilateral filter, using functions like cv2.GaussianBlur(), cv2.medianBlur(), and cv2.bilateralFilter(), respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8038b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Gaussian Blur\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image4 = cv2.imread('C:/Users/91630/Downloads/img1.jpg',1)\n",
    "\n",
    "\n",
    "# Display the original image\n",
    "cv2.imshow('Original Image', image4)\n",
    "\n",
    "# Apply Gaussian blur filtering\n",
    "ksize = (9, 9)  # Kernel size (odd number)\n",
    "sigmaX = 0      # Standard deviation along X-axis (0 means calculated based on ksize)\n",
    "sigmaY = 0      # Standard deviation along Y-axis (0 means calculated based on ksize)\n",
    "blurred_image = cv2.GaussianBlur(image4, ksize, sigmaX, sigmaY)\n",
    "\n",
    "# Display the blurred image\n",
    "cv2.imshow('Blurred Image', blurred_image)\n",
    "\n",
    "# Wait for a key press and then close all open windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cd8ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "##thresholding\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image5 = cv2.imread('C:/Users/91630/Downloads/img1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "# Display the original image\n",
    "cv2.imshow('Original Image', image5)\n",
    "\n",
    "# Apply thresholding\n",
    "ret, thresh_image = cv2.threshold(image5, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Display the thresholded image\n",
    "cv2.imshow('Thresholded Image', thresh_image)\n",
    "\n",
    "# Wait for a key press and then close all open windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b514199",
   "metadata": {},
   "source": [
    "### Image drawing: OpenCV provides functions for drawing various shapes, lines, and texts on images. Functions like cv2.line(), cv2.rectangle(), cv2.circle(), and cv2.putText() can be used to draw lines, rectangles, circles, and texts, respectively, on images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ebdb17",
   "metadata": {},
   "source": [
    "# How do we save images in OpenCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c769ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('image.png',image5)     ## We can save images in whichever format we want just by specifying it \n",
    "cv2.imwrite('image.jpg',image5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4a0999",
   "metadata": {},
   "source": [
    "# Face Detection using HAAR Cascade Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b15d745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:18: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:18: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\91630\\AppData\\Local\\Temp\\ipykernel_8816\\3029917752.py:18: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "## face detection\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "# We point OpenCV's CascadeClassifier function to where our \n",
    "# classifier (XML file format) is stored\n",
    "face_classifier = cv2.CascadeClassifier('C:/Users/91630/OneDrive/Documents/FP/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load our image then convert it to grayscale\n",
    "image = cv2.imread('C:/Users/91630/OneDrive/Documents/FP/Trumph.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Our classifier returns the ROI of the detected face as a tuple\n",
    "# It stores the top left coordinate and the bottom right coordiantes\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# When no faces detected, face_classifier returns and empty tuple\n",
    "if faces is ():\n",
    "    print(\"No faces found\")\n",
    "\n",
    "# We iterate through our faces array and draw a rectangle\n",
    "# over each face in faces\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image, (x,y), (x+w,y+h), (100,0,200), 2)\n",
    "    #cv2.circle(image, (100, 200), 50, (127, 0, 255), 2)\n",
    "    cv2.imshow('Face Detection', image)\n",
    "    #cv2.imshow(\"Image with Circle\", image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea1a72",
   "metadata": {},
   "source": [
    "# Car & Pedestrian Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77948dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Car detection\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Create our body classifier\n",
    "car_classifier = cv2.CascadeClassifier('C:/Users/91630/OneDrive/Documents/FP/haarcascade_car.xml')\n",
    "\n",
    "# Initiate video capture for video file\n",
    "cap = cv2.VideoCapture('C:/Users/91630/OneDrive/Documents/FP/car.MP4')\n",
    "\n",
    "\n",
    "# Loop once video is successfully loaded\n",
    "while cap.isOpened():\n",
    "    \n",
    "    time.sleep(.05)\n",
    "    # Read first frame\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "   \n",
    "    # Pass frame to our car classifier\n",
    "    cars = car_classifier.detectMultiScale(gray, 1.4, 2)\n",
    "    \n",
    "    # Extract bounding boxes for any bodies identified\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        cv2.imshow('Cars', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78943432",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fullbody recognition (pedestrian recognition)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create our body classifier\n",
    "body_classifier = cv2.CascadeClassifier('C:/Users/91630/OneDrive/Documents/FP/haarcascade_fullbody.xml')\n",
    "\n",
    "# Initiate video capture for video file\n",
    "cap = cv2.VideoCapture('C:/Users/91630/OneDrive/Documents/FP/pedestrian.MP4')\n",
    "\n",
    "# Loop once video is successfully loaded\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # Read first frame\n",
    "    ret, frame = cap.read()\n",
    "    #frame = cv2.resize(frame, None,fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Pass frame to our body classifier\n",
    "    bodies = body_classifier.detectMultiScale(gray, 1.2, 3)\n",
    "    \n",
    "    # Extract bounding boxes for any bodies identified\n",
    "    for (x,y,w,h) in bodies:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        cv2.imshow('Pedestrians', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f2a2f",
   "metadata": {},
   "source": [
    "# Let's make a live face & eye detection, keeping the face inview at all times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3dd5b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Loading the cascades\n",
    "face_cascade = cv2.CascadeClassifier('C:/Users/91630/OneDrive/Documents/FP/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('C:/Users/91630/OneDrive/Documents/FP/haarcascade_eye.xml')\n",
    "\n",
    "# Defining a function that will do the detections\n",
    "def detect(gray, frame):\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 3)\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "    return frame\n",
    "\n",
    "# Doing some Face Recognition with the webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    canvas = detect(gray, frame)\n",
    "    cv2.imshow('Video', canvas)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('k'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9c8798",
   "metadata": {},
   "source": [
    "## THE END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c329bd45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
